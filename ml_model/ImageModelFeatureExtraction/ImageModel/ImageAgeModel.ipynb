{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqwjilu0iB5s",
        "outputId": "91d9d2a5-f91c-4eec-fad7-57a41a434652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ba77UQl24FgekMX58BrNtba_zcFAo1Dv\n",
            "From (redirected): https://drive.google.com/uc?id=1ba77UQl24FgekMX58BrNtba_zcFAo1Dv&confirm=t&uuid=51627ecd-4e50-44eb-9e0b-f1a267f89fa9\n",
            "To: /content/images.zip\n",
            "100% 273M/273M [00:03<00:00, 86.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import gdown # Library to download files from Google Drive\n",
        "!gdown 1ba77UQl24FgekMX58BrNtba_zcFAo1Dv # Google Drive ID of the zip file to be downloaded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kc-whf_TnQwv"
      },
      "outputs": [],
      "source": [
        "!unzip -oq images # Unzip the file downloaded. Options -o and -q overwrites the files if exists already and disables printing out the extracted files, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEAUVfFblvle"
      },
      "outputs": [],
      "source": [
        "\n",
        "root_dir = '/content/images'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "X3NGIIAB5Dl8",
        "outputId": "be531dea-b421-4032-d025-bf71b699cd84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17yEXHnf1Q7KAJyqvIOFzFWNg1nh0oJhc\n",
            "To: /content/ad_responses.json\n",
            "100%|██████████| 23.1M/23.1M [00:00<00:00, 112MB/s] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ad_responses.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "# Define the Google Drive file ID for the responses.json file\n",
        "file_id = '17yEXHnf1Q7KAJyqvIOFzFWNg1nh0oJhc'\n",
        "\n",
        "# Define the output path for the downloaded file\n",
        "output_path = '/content/ad_responses.json'\n",
        "\n",
        "# Download the file using gdown\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', output_path, quiet=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LvGUsA3FczEx"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load the JSON data\n",
        "responses_file = '/content/ad_responses.json'\n",
        "with open(responses_file, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Create a dictionary to map '_id' to ad_info for faster lookup\n",
        "ad_info_dict = {info['_id']: info for info in data.values() if '_id' in info}\n",
        "# Define the root directory for images\n",
        "images_dir = '/content/images'\n",
        "\n",
        "# Define the target dimensions for resizing images (lower resolution for efficiency)\n",
        "target_width = 512   # Lower resolution\n",
        "target_height = 512  # Lower resolution\n",
        "\n",
        "# Initialize lists to store calculated and extracted features\n",
        "campaign_data = []\n",
        "\n",
        "# Define the function to calculate age group percentages\n",
        "def calculate_age_group(demographics):\n",
        "    age_groups = {\n",
        "        'age-13-17': 0,\n",
        "        'age-18-24': 0,\n",
        "        'age-25-34': 0,\n",
        "        'age-35-44': 0,\n",
        "        'age-45-54': 0,\n",
        "        'age-55-64': 0,\n",
        "        'age-65+': 0\n",
        "    }\n",
        "    for demo in demographics:\n",
        "        age = demo['age']\n",
        "        percentage = float(demo['percentage'])\n",
        "        if age == '18-24':\n",
        "            age_groups['age-18-24'] += percentage\n",
        "        elif age == '25-34':\n",
        "            age_groups['age-25-34'] += percentage\n",
        "        elif age == '35-44':\n",
        "            age_groups['age-35-44'] += percentage\n",
        "        elif age == '45-54':\n",
        "            age_groups['age-45-54'] += percentage\n",
        "        elif age == '55-64':\n",
        "            age_groups['age-55-64'] += percentage\n",
        "        elif age == '65+':\n",
        "            age_groups['age-65+'] += percentage\n",
        "        else:\n",
        "            age_groups['age-13-17'] += percentage  # Assuming all other ages fall into this category\n",
        "    return age_groups\n",
        "\n",
        "# Iterate through each image in the images directory\n",
        "for filename in os.listdir(images_dir):\n",
        "    if filename.endswith(\".jpg\"):  # Check if the file is a JPEG image\n",
        "        image_id = filename.split('.')[0]  # Extract ID from filename\n",
        "        for key, value in ad_info_dict.items():\n",
        "            if '_id' in value and value['_id'] == image_id:\n",
        "                ad_info = value\n",
        "                image_path = os.path.join(images_dir, filename)\n",
        "\n",
        "                # Load and preprocess the image\n",
        "                with Image.open(image_path) as img:\n",
        "                    img = img.convert('RGB')  # Convert image to RGB format\n",
        "                    img = img.resize((target_width, target_height))  # Resize image to lower resolution\n",
        "                    img_array = np.array(img)  # Convert image to numpy array\n",
        "\n",
        "                # Process only the necessary data to reduce memory load\n",
        "                avg_spend = np.mean([int(ad_info.get(\"spend\", {}).get(\"lower_bound\", 0)), int(ad_info.get(\"spend\", {}).get(\"upper_bound\", 0))])\n",
        "                avg_impressions = np.mean([int(ad_info.get(\"impressions\", {}).get(\"lower_bound\", 0)), int(ad_info.get(\"impressions\", {}).get(\"upper_bound\", 0))])\n",
        "                cost_per_impression = avg_spend / avg_impressions if avg_impressions > 0 else float('inf')\n",
        "\n",
        "                # Calculate age group percentages\n",
        "                age_groups = calculate_age_group(ad_info.get('demographic_distribution', []))\n",
        "\n",
        "                # Append only necessary info to reduce memory footprint\n",
        "                campaign_data.append({\n",
        "                    \"ad_id\": ad_info.get('_id', ''),\n",
        "                    \"cpi\": cost_per_impression,\n",
        "                    \"image_data\": img_array.flatten().tolist(),  # Flatten and convert to list to minimize size\n",
        "                    \"age_groups\": age_groups\n",
        "                })\n",
        "                break\n",
        "\n",
        "# Save the normalized data\n",
        "with open('/content/campaign_data.pkl', 'wb') as f:\n",
        "    pickle.dump(campaign_data, f)\n",
        "\n",
        "# Clear the large variables from memory\n",
        "del campaign_data\n",
        "del data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6LTXfo58bRoF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, image_filenames, labels_cpi, labels_age_groups, image_directory, batch_size):\n",
        "        self.image_filenames = image_filenames  # This should be a list of IDs\n",
        "        self.labels_cpi = labels_cpi  # This should be a dictionary {id: cpi}\n",
        "        self.labels_age_groups = labels_age_groups  # This should be a dictionary {id: age_group_index}\n",
        "        self.image_directory = image_directory\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "      batch_y_cpi = [self.labels_cpi[x] for x in batch_x if x in self.labels_cpi]\n",
        "      batch_y_age_groups = [to_categorical(self.labels_age_groups[x], num_classes=7) for x in batch_x if x in self.labels_age_groups]\n",
        "\n",
        "      images = []\n",
        "      for file_id in batch_x:\n",
        "          file_path = os.path.join(self.image_directory, f'{file_id}.jpg')\n",
        "          if os.path.exists(file_path):\n",
        "              img = Image.open(file_path)\n",
        "              img = img.resize((512, 512), Image.ANTIALIAS)  # Using ANTIALIAS for better resizing quality\n",
        "              img_array = np.array(img) / 255.0  # Normalize the images\n",
        "              if img_array.shape != (512, 512, 3):  # Ensure each image has the correct shape\n",
        "                  print(f\"Debug: Incorrect image shape {img_array.shape} for file: {file_path}\")\n",
        "                  img_array = np.zeros((512, 512, 3))  # Correct the shape with a zero array\n",
        "              images.append(img_array)\n",
        "          else:\n",
        "              print(f\"Debug: File not found, using zero array for: {file_path}\")\n",
        "              images.append(np.zeros((512, 512, 3)))  # Ensure the shape matches expected input dimensions\n",
        "\n",
        "      images = np.stack(images)  # Ensures all images are the same shape\n",
        "      batch_y_cpi = np.array(batch_y_cpi, dtype=np.float32)\n",
        "\n",
        "      if batch_y_age_groups:  # Check if list is not empty before stacking\n",
        "          batch_y_age_groups = np.stack(batch_y_age_groups)\n",
        "      else:\n",
        "          print(\"Debug: No age group data available for this batch.\")\n",
        "          batch_y_age_groups = np.zeros((len(batch_x), 7))  # Create a placeholder with zeros\n",
        "\n",
        "      print(\"Images array shape after conversion:\", images.shape)\n",
        "      print(\"CPI labels shape after conversion:\", batch_y_cpi.shape)\n",
        "      print(\"Age groups shape after conversion:\", batch_y_age_groups.shape)\n",
        "\n",
        "      return images, [batch_y_cpi, batch_y_age_groups]\n",
        "\n",
        "\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.image_filenames))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, image_filenames_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size), dtype=float)\n",
        "\n",
        "        # Generate data\n",
        "        for i, image_filename in enumerate(image_filenames_temp):\n",
        "            # Store sample\n",
        "            img = load_img(os.path.join(self.image_directory, image_filename + '.jpg'), target_size=self.dim)\n",
        "            X[i,] = img_to_array(img) / 255.0\n",
        "\n",
        "            # Store class\n",
        "            y[i] = self.labels[image_filename]\n",
        "\n",
        "        return X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Or7aFRU0YOCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b495a6-6e6f-4469-85a7-32c444da898e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ad ID: 401171250412601\n",
            "Cost Per Impression (CPI): 0.003089096525630047\n",
            "Sample Image Data (flattened): [105, 90, 83, 106, 91, 84, 107, 92, 85, 107]\n",
            "Age Group Percentages:\n",
            "age-13-17: 0.00%\n",
            "age-18-24: 15.72%\n",
            "age-25-34: 24.87%\n",
            "age-35-44: 19.55%\n",
            "age-45-54: 16.11%\n",
            "age-55-64: 13.81%\n",
            "age-65+: 9.95%\n",
            "\n",
            "\n",
            "Ad ID: 1446433942154722\n",
            "Cost Per Impression (CPI): 0.01315270080368844\n",
            "Sample Image Data (flattened): [175, 184, 199, 175, 184, 199, 175, 184, 199, 177]\n",
            "Age Group Percentages:\n",
            "age-13-17: 0.00%\n",
            "age-18-24: 6.28%\n",
            "age-25-34: 13.53%\n",
            "age-35-44: 20.36%\n",
            "age-45-54: 23.23%\n",
            "age-55-64: 22.72%\n",
            "age-65+: 13.88%\n",
            "\n",
            "\n",
            "Ad ID: 2115518362093406\n",
            "Cost Per Impression (CPI): 0.017320230936412485\n",
            "Sample Image Data (flattened): [238, 238, 238, 238, 238, 238, 238, 238, 238, 238]\n",
            "Age Group Percentages:\n",
            "age-13-17: 0.00%\n",
            "age-18-24: 3.99%\n",
            "age-25-34: 29.99%\n",
            "age-35-44: 28.30%\n",
            "age-45-54: 16.98%\n",
            "age-55-64: 11.25%\n",
            "age-65+: 9.48%\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Load the processed data from disk\n",
        "with open('/content/campaign_data.pkl', 'rb') as f:\n",
        "    campaign_data = pickle.load(f)\n",
        "\n",
        "# Print the first few entries of the campaign data to verify\n",
        "for campaign in campaign_data[:3]:  # Adjust the range as needed for more samples\n",
        "    print(\"Ad ID:\", campaign[\"ad_id\"])\n",
        "    print(\"Cost Per Impression (CPI):\", campaign[\"cpi\"])\n",
        "    print(\"Sample Image Data (flattened):\", campaign[\"image_data\"][:10])  # Show only the first 10 pixels to keep output manageable\n",
        "    print(\"Age Group Percentages:\")\n",
        "    for age_group, percentage in campaign[\"age_groups\"].items():\n",
        "        print(f\"{age_group}: {percentage:.2%}\")\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkfJ4SWO1odf",
        "outputId": "22ba7655-6fc1-40e1-e0d3-4b1f59bfbacc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n",
            "TensorFlow will run on CPU\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check TensorFlow GPU usage\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"TensorFlow will run on GPU\")\n",
        "else:\n",
        "    print(\"TensorFlow will run on CPU\")\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fedkgJPvcqG4",
        "outputId": "162c9638-1411-4d02-e9ab-ab4785b58963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 512, 512, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)   (None, 1)                    1300758   ['input_2[0][0]']             \n",
            "                                                          41                                      \n",
            "                                                                                                  \n",
            " sequential_3 (Sequential)   (None, 7)                    1300766   ['input_2[0][0]']             \n",
            "                                                          15                                      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 260152456 (992.40 MB)\n",
            "Trainable params: 260152456 (992.40 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-091371c96b51>:28: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  img = img.resize((512, 512), Image.ANTIALIAS)  # Using ANTIALIAS for better resizing quality\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Debug: Incorrect image shape (512, 512, 4) for file: /content/images/1907063079596864.jpg\n",
            "Debug: No age group data available for this batch.\n",
            "Images array shape after conversion: (10, 512, 512, 3)\n",
            "CPI labels shape after conversion: (0,)\n",
            "Age groups shape after conversion: (10, 7)\n",
            "Epoch 1/10\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "labels_cpi = {item['ad_id']: item['cpi'] for item in campaign_data}\n",
        "labels_age_groups = {item['ad_id']: list(item['age_groups'].values()) for item in campaign_data}  # Ensure this mapping is correct\n",
        "\n",
        "image_filenames = [item['ad_id'] for item in campaign_data]  # IDs should match exactly in labels\n",
        "\n",
        "# Splitting the dataset\n",
        "image_filenames_train, image_filenames_test, labels_cpi_train, labels_cpi_test, labels_age_groups_train, labels_age_groups_test = train_test_split(\n",
        "    image_filenames, [labels_cpi[id] for id in image_filenames], [labels_age_groups[id] for id in image_filenames], test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the generator for CPI\n",
        "batch_size = 10  # Depends on your available memory\n",
        "# Example instantiation and model fitting\n",
        "train_generator = DataGenerator(image_filenames_train, labels_cpi_train, labels_age_groups_train, '/content/images', batch_size)\n",
        "test_generator = DataGenerator(image_filenames_test, labels_cpi_test, labels_age_groups_test, '/content/images', batch_size)\n",
        "\n",
        "# Define your model's input shape based on the data dimensions you will train on\n",
        "input_shape = (512, 512, 3)  # Modify according to your resized image dimensions\n",
        "\n",
        "# Define the model for CPI prediction\n",
        "model_cpi = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='linear', name='cpi_output')  # Linear activation for regression\n",
        "])\n",
        "\n",
        "# Compile the model for CPI prediction\n",
        "model_cpi.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mean_squared_error'])\n",
        "\n",
        "# Define the model for age distribution prediction\n",
        "model_age_groups = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(7, activation='softmax', name='age_output')  # Softmax activation for classification\n",
        "])\n",
        "\n",
        "# Compile the model for age distribution prediction\n",
        "model_age_groups.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Combine both models into a single model\n",
        "combined_model_input = tf.keras.Input(shape=input_shape)\n",
        "cpi_output = model_cpi(combined_model_input)\n",
        "age_output = model_age_groups(combined_model_input)\n",
        "\n",
        "combined_model = Model(inputs=combined_model_input, outputs=[cpi_output, age_output])\n",
        "\n",
        "# Compile the combined model with appropriate loss functions and metrics\n",
        "combined_model.compile(optimizer='adam', loss=['mean_absolute_error', 'categorical_crossentropy'], metrics=['mean_squared_error', 'accuracy'])\n",
        "\n",
        "# Show the model structure\n",
        "combined_model.summary()\n",
        "\n",
        "# Now use this combined model with both generators directly in model.fit\n",
        "\n",
        "combined_model.fit(train_generator, epochs=10, validation_data=test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RbjOBRPp6Lal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#abs - squared error\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_mae = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Mean Absolute Error (MAE): {test_mae}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87Eqs4-eCaap",
        "outputId": "c2ed2efc-da99-4673-a752-5422d8045af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 5s 193ms/step - loss: 0.0160 - mean_squared_error: 6.6541e-04\n",
            "Test Loss: 0.016047503799200058\n",
            "Mean Absolute Error (MAE): 0.0006654096068814397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY-w5IVOC3Hc",
        "outputId": "158d88a4-886d-4068-b65d-6f2e2fef31c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 2s 164ms/step - loss: 0.0280 - mean_squared_error: 0.0024\n",
            "Test Loss: 0.028036927804350853\n",
            "Mean Absolute Error (MAE): 0.0024414174258708954\n"
          ]
        }
      ],
      "source": [
        "#squared error - abs error\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_mae = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Mean Absolute Error (MAE): {test_mae}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cpis = []\n",
        "for batch_images, batch_labels in test_generator:\n",
        "    test_cpis.extend(batch_labels)  # Assuming batch_images contains the image filenames, which are the IDs\n",
        "\n",
        "# Now test_ids contains all the IDs in the test generator\n",
        "print(\"CPIs in the test generator:\", test_cpis)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf0_6ieRQFsT",
        "outputId": "8fa42e01-835c-433f-ffca-ad2ea07afd55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPIs in the test generator: [0.0024422276493947766, 0.023332682221788147, 0.014705302767825158, 0.007775572834606299, 0.01425755021572045, 0.019934662310820722, 0.009998957893639889, 0.05545060562284698, 0.011997365326307536, 0.013843119517290822, 0.0033320044426725904, 0.007615970459266097, 0.06355123193017546, 0.09969989996665556, 0.01425755021572045, 0.019971999199977143, 0.01980396079215843, 0.0990990990990991, 0.017589269957056296, 0.009997799995111101, 0.008440037511277828, 0.011809198265438777, 0.03322591399044338, 0.009998199996727266, 0.09969989996665556, 0.00908730577202099, 0.149999, 0.04396175847033881, 0.0057842409696893145, 0.033011003667889297, 0.06469487876327956, 0.009072892234404262, 0.0598119623924785, 0.006921549110075554, 0.016345751740940745, 0.005210800568450971, 0.01999849230537278, 0.03683196665228055, 0.015551180227467678, 0.011960478419136765, 0.06537742598019984, 0.0598119623924785, 0.019934662310820722, 0.00900081825620511, 0.0646508618154009, 0.011001222358039782, 0.01461386863672098, 0.008635462395874906, 0.035961438457538304, 0.04396175847033881, 0.033011003667889297, 0.027184289480861896, 0.011960478419136765, 0.004884466153182903, 0.011960478419136765, 0.019986933159108787, 0.01636005949112542, 0.009072892234404262, 0.01425755021572045, 0.0066622518322303655, 0.026152347926689117, 0.0542586931055173, 0.05545060562284698, 0.09969989996665556, 0.011089135314118091, 0.007615970459266097, 0.009463257507973768, 0.011960478419136765, 0.047269262797319266, 0.019934662310820722, 0.033011003667889297, 0.009997799995111101, 0.019982181494208984, 0.07140204005828737, 0.01425755021572045, 0.008817698927640751, 0.019984922844966845, 0.004600070770319544, 0.019971999199977143, 0.011106716029849022, 0.005993373289155261, 0.017589269957056296, 0.033011003667889297, 0.016664481476625505, 0.014144877839691384, 0.011960478419136765, 0.026264540238959945, 0.028884572820323647, 0.01980396079215843, 0.01980396079215843, 0.017589269957056296, 0.13153323859150481, 0.017270940492619076, 0.03331185137447499, 0.04332695551303675, 0.033011003667889297, 0.03679141007421443, 0.0990990990990991, 0.0598119623924785, 0.011809198265438777, 0.04282979513700391, 0.02444010862270499, 0.011089135314118091, 0.007775572834606299, 0.008666005777337185, 0.04665395538607182, 0.04999269225147886, 0.03420544318654309, 0.026464861558009166, 0.009072892234404262, 0.0076770411852490035, 0.013830982015107924, 0.09995262908574136, 0.03140089716849053, 0.01997822173826085, 0.007551144671754097, 0.03140089716849053, 0.027255041000745467, 0.0053769644381879865, 0.003517688443393452, 0.01980396079215843, 0.009990999918181075, 0.005773358992706634, 0.02935466792164245, 0.00587065730185061, 0.02271838834898499, 0.03322591399044338, 0.013627396612696479, 0.011960478419136765, 0.02726919006978207, 0.01980396079215843, 0.04396175847033881, 0.03322591399044338, 0.0990990990990991, 0.017320230936412485, 0.0022000488899753326, 0.01425755021572045, 0.0990990990990991, 0.015551180227467678, 0.019960798431937276, 0.01999643635067764, 0.019971999199977143, 0.0184158863994021, 0.027184289480861896, 0.00900081825620511, 0.019934662310820722, 0.011332015109353478, 0.01999738665969776, 0.038387568274482656, 0.03090732892241622, 0.028884572820323647, 0.026305540058316403, 0.0990990990990991, 0.009990999918181075, 0.008543101231463755, 0.011960478419136765, 0.014144877839691384, 0.011960478419136765, 0.005227708392948901, 0.0990990990990991, 0.008543101231463755, 0.014653528713716182, 0.019982181494208984, 0.008543101231463755, 0.015737670403705457, 0.01425755021572045, 0.016666011110674075, 0.04221796541317961, 0.0990990990990991, 0.013627396612696479, 0.016345751740940745, 0.019982181494208984, 0.011089135314118091, 0.020582474014553025, 0.0990990990990991, 0.026138863674825766, 0.011960478419136765, 0.022726384296712997, 0.011960478419136765, 0.023001769366874376, 0.009072892234404262, 0.011089135314118091, 0.05545060562284698, 0.064999, 0.011960478419136765, 0.055534567434831886, 0.0990990990990991, 0.019995644425086334, 0.019982181494208984, 0.011106716029849022, 0.00543646248113602, 0.00543646248113602, 0.04999269225147886, 0.027184289480861896, 0.019960798431937276, 0.033011003667889297, 0.009998476920733725, 0.01997822173826085, 0.05293003447099378, 0.0013288947950879783, 0.033011003667889297, 0.022341439311050718, 0.014442254316120702, 0.019960798431937276, 0.019995644425086334, 0.054999, 0.01315270080368844, 0.01198682649101988, 0.064999, 0.026305540058316403, 0.0598119623924785, 0.033011003667889297, 0.0333290370179423, 0.04411202418837758, 0.024999, 0.003517688443393452, 0.02796111844473779, 0.011089135314118091, 0.0058238719924701456, 0.04999269225147886, 0.013069331302548481, 0.016345751740940745, 0.0411200658862286, 0.02796111844473779, 0.0473583932462447, 0.034999, 0.019960798431937276, 0.019960798431937276, 0.02271838834898499, 0.009992384556804283, 0.02796111844473779, 0.01198682649101988, 0.0990990990990991, 0.011960478419136765, 0.024999, 0.019960798431937276, 0.02796111844473779, 0.028884572820323647, 0.014144877839691384, 0.029993533290221936]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Assuming 'model' and 'test_generator' are defined and loaded appropriately\n",
        "# Load your model if it is not already loaded\n",
        "# model = load_model('path_to_your_model.h5')\n",
        "\n",
        "# Extract labels and predictions without assuming reset functionality\n",
        "test_cpis = []\n",
        "predictions = []\n",
        "for batch_images, batch_labels in test_generator:\n",
        "    test_cpis.extend(batch_labels)\n",
        "    predictions.extend(model.predict_on_batch(batch_images))\n",
        "\n",
        "# Convert data to numpy arrays for easier manipulation\n",
        "test_cpis = np.array(test_cpis)\n",
        "predictions = np.array(predictions)\n",
        "\n",
        "# Initialize accuracy counts for each order position\n",
        "num_trials = 500\n",
        "accuracy_counts = np.zeros(4)\n",
        "\n",
        "# Print lengths to verify data sizes\n",
        "print(\"Predicted data length:\", len(predictions))\n",
        "print(\"Actual data length:\", len(test_cpis))\n",
        "\n",
        "# Validate if we have enough elements to randomly pick 4\n",
        "if len(predictions) >= 4 and len(test_cpis) >= 4:\n",
        "    for _ in range(num_trials):\n",
        "        # Randomly pick 4 indices ensuring no out of bound error\n",
        "        indices = np.arange(min(len(predictions), len(test_cpis)))\n",
        "        selected_indices = shuffle(indices)[:4]  # No fixed seed for true randomness each trial\n",
        "\n",
        "        # Extract selected predictions and actual values\n",
        "        selected_predictions = predictions[selected_indices]\n",
        "        selected_actuals = test_cpis[selected_indices]\n",
        "\n",
        "        # Order by predictions\n",
        "        order_pred_indices = np.argsort(selected_predictions[:, 0])  # Assuming predictions are in the first column\n",
        "        order_actual_indices = np.argsort(selected_actuals)\n",
        "\n",
        "        # Compare orders\n",
        "        accuracy_positions = [1 if pred_i == act_i else 0 for pred_i, act_i in zip(order_pred_indices, order_actual_indices)]\n",
        "        accuracy_counts += accuracy_positions\n",
        "\n",
        "    # Calculate average accuracies for each order\n",
        "    average_accuracies = accuracy_counts / num_trials\n",
        "    print(\"Average Accuracy at first position:\", average_accuracies[0])\n",
        "    print(\"Average Accuracy at second position:\", average_accuracies[1])\n",
        "    print(\"Average Accuracy at third position:\", average_accuracies[2])\n",
        "    print(\"Average Accuracy at fourth position:\", average_accuracies[3])\n",
        "else:\n",
        "    print(\"Not enough data points to select 4 unique values. Please ensure at least 4 data points are available.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-ESFC4rZJhD",
        "outputId": "2db588e2-bc43-49d9-ff48-d84247157385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted data length: 240\n",
            "Actual data length: 240\n",
            "Average Accuracy at first position: 0.354\n",
            "Average Accuracy at second position: 0.278\n",
            "Average Accuracy at third position: 0.274\n",
            "Average Accuracy at fourth position: 0.318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# First, gather all predictions and actuals\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for batch_images, batch_labels in test_generator:\n",
        "    preds = model.predict_on_batch(batch_images)\n",
        "    y_pred.extend(preds)\n",
        "    y_true.extend(batch_labels)\n",
        "\n",
        "# Convert lists to numpy arrays for easier manipulation\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# Calculate the concordance index, treating it similar to AUC calculation\n",
        "def calculate_concordance_index(y_true, y_pred):\n",
        "    n = 0\n",
        "    h_sum = 0\n",
        "    for i in range(len(y_true)):\n",
        "        for j in range(i + 1, len(y_true)):\n",
        "            if y_true[i] != y_true[j]:\n",
        "                n += 1\n",
        "                if (y_pred[i] > y_pred[j] and y_true[i] > y_true[j]) or (y_pred[i] < y_pred[j] and y_true[i] < y_true[j]):\n",
        "                    h_sum += 1\n",
        "                elif y_pred[i] == y_pred[j]:\n",
        "                    h_sum += 0.5\n",
        "    return h_sum / n if n > 0 else 0\n",
        "\n",
        "# Calculate the C-index\n",
        "c_index = calculate_concordance_index(y_true, y_pred)\n",
        "print(\"Concordance Index:\", c_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAFyuYpqgd0h",
        "outputId": "af73d1bd-a241-46a9-cfa1-4e702f7acd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concordance Index: 0.5634373019784552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#abs error - squared error\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test_predict = model.predict(test_generator)\n",
        "count = 0\n",
        "for i in range (0,12):\n",
        "  print(test_predict[i])\n",
        "  print(test_cpis[i])\n",
        "# Create the scatter plot\n",
        "plt.figure()\n",
        "plt.scatter(test_predict, test_cpis, marker=\"+\")\n",
        "plt.xlabel(\"Predicted Value\")\n",
        "plt.ylabel(\"True Value\")\n",
        "\n",
        "# Add a reference line\n",
        "plt.plot([0, 0.1], [0, 0.1], \"r--\")  # Assuming the range of values is -60 to 60, adjust as needed\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "id": "_a4KF_RAPs2H",
        "outputId": "860acc36-5a34-4b51-cc6f-20885dfa526a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 4s 159ms/step\n",
            "[0.01753137]\n",
            "0.04581253201964348\n",
            "[0.03685854]\n",
            "0.035091358243902145\n",
            "[0.03686155]\n",
            "0.019425027160813655\n",
            "[0.03512993]\n",
            "0.023563622836356286\n",
            "[0.03504461]\n",
            "0.034026999709255636\n",
            "[0.0525687]\n",
            "0.08869409321693661\n",
            "[0.02866]\n",
            "0.07770218072903522\n",
            "[0.04326495]\n",
            "0.1154099091960989\n",
            "[0.033433]\n",
            "0.014140393112971727\n",
            "[0.03369978]\n",
            "0.08869409321693661\n",
            "[0.03082199]\n",
            "0.03898425183181553\n",
            "[0.03534913]\n",
            "0.011570060642888829\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "# Mount Google Drive\n",
        "shutil.rmtree('/content/drive', ignore_errors=True)\n",
        "drive.mount('/content/drive')\n",
        "# Save the model to Google Drive\n",
        "model.save('/content/drive/MyDrive/path/to/save/model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxgkZ5KF6R05",
        "outputId": "b661fa12-47bc-423d-83a4-7d090dfe4bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}