{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import gdown # Library to download files from Google Drive\n",
        "!gdown 1JdGaXmUnItfCn8ucn_5kBfDeh3NzrmMs # Google Drive ID of the zip file to be downloaded\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqwjilu0iB5s",
        "outputId": "2162f02d-f703-4ce9-c11d-a8e3fe3b6130"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1JdGaXmUnItfCn8ucn_5kBfDeh3NzrmMs\n",
            "From (redirected): https://drive.google.com/uc?id=1JdGaXmUnItfCn8ucn_5kBfDeh3NzrmMs&confirm=t&uuid=4d122176-9728-40c1-8b12-bc46f85e2176\n",
            "To: /content/images.zip adlı dosyanın kopyası\n",
            "100% 128M/128M [00:01<00:00, 74.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -oq images # Unzip the file downloaded. Options -o and -q overwrites the files if exists already and disables printing out the extracted files, respectively."
      ],
      "metadata": {
        "id": "Kc-whf_TnQwv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "root_dir = '/content/images'\n"
      ],
      "metadata": {
        "id": "fEAUVfFblvle"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, UnidentifiedImageError\n",
        "import os\n",
        "\n",
        "root_dir = '/content/images'\n",
        "output_dir = '/content/cropped_images'\n",
        "\n",
        "# Function to calculate average resolution of images in a directory\n",
        "def calculate_average_resolution(directory):\n",
        "    total_width = 0\n",
        "    total_height = 0\n",
        "    num_images = 0\n",
        "\n",
        "    # Loop through each file in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        try:\n",
        "            # Check if the file is an image\n",
        "            if os.path.isfile(filepath) and any(filename.lower().endswith(ext) for ext in ['.png', '.jpg', '.jpeg']):\n",
        "                # Open the image and get its dimensions\n",
        "                with Image.open(filepath) as img:\n",
        "                    width, height = img.size\n",
        "                    total_width += width\n",
        "                    total_height += height\n",
        "                    num_images += 1\n",
        "        except (UnidentifiedImageError, OSError):\n",
        "            print(f\"Unable to process image file: {filename}\")\n",
        "            continue\n",
        "\n",
        "    if num_images == 0:\n",
        "        print(\"No images found in the directory.\")\n",
        "        return None\n",
        "    else:\n",
        "        avg_width = total_width // num_images\n",
        "        avg_height = total_height // num_images\n",
        "        return (avg_width, avg_height, num_images)\n",
        "\n",
        "# Function to create the output directory if it doesn't exist\n",
        "def create_output_directory(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# Function to crop images in a directory to a specified resolution\n",
        "def crop_images_to_resolution(directory, target_resolution):\n",
        "    for filename in os.listdir(directory):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        try:\n",
        "            # Check if the file is an image\n",
        "            if os.path.isfile(filepath) and any(filename.lower().endswith(ext) for ext in ['.png', '.jpg', '.jpeg']):\n",
        "                # Open the image and crop it to the target resolution\n",
        "                with Image.open(filepath) as img:\n",
        "                    img = img.crop((0, 0, target_resolution[0], target_resolution[1]))\n",
        "                    img.save(os.path.join(output_dir, filename))\n",
        "        except (UnidentifiedImageError, OSError):\n",
        "            print(f\"Unable to process image file: {filename}\")\n",
        "            continue\n",
        "\n",
        "# Calculate average resolution and total number of images\n",
        "result = calculate_average_resolution(root_dir)\n",
        "\n",
        "if result:\n",
        "    avg_resolution, num_images = result[:2], result[2]\n",
        "    print(f\"Total number of images: {num_images}\")\n",
        "    print(f\"Average resolution: {avg_resolution[0]}x{avg_resolution[1]} pixels\")\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    create_output_directory(output_dir)\n",
        "\n",
        "    # Crop images to average resolution\n",
        "    crop_images_to_resolution(root_dir, avg_resolution)\n",
        "    print(\"Images cropped to average resolution.\")\n",
        "else:\n",
        "    print(\"Unable to calculate average resolution.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6-Go7XspCmT",
        "outputId": "a754279a-5901-410f-b07f-1ec8c3518073"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images: 636\n",
            "Average resolution: 1194x867 pixels\n",
            "Unable to process image file: 309519166320626.jpg\n",
            "Unable to process image file: 285424975595779.jpg\n",
            "Unable to process image file: 186076198984051.jpg\n",
            "Unable to process image file: 2167198373551810.jpg\n",
            "Unable to process image file: 695766190760630.jpg\n",
            "Unable to process image file: 320619618717364.jpg\n",
            "Unable to process image file: 676687789384754.jpg\n",
            "Unable to process image file: 430743550786558.jpg\n",
            "Unable to process image file: 1723492444426167.jpg\n",
            "Unable to process image file: 499615317172296.jpg\n",
            "Unable to process image file: 728334204189811.jpg\n",
            "Unable to process image file: 253935178579446.jpg\n",
            "Unable to process image file: 346700996063593.jpg\n",
            "Unable to process image file: 1684090145051513.jpg\n",
            "Unable to process image file: 176574166615555.jpg\n",
            "Unable to process image file: 1212019935620496.jpg\n",
            "Unable to process image file: 936632113212421.jpg\n",
            "Unable to process image file: 1969722553066031.jpg\n",
            "Images cropped to average resolution.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# Define the Google Drive file ID for the responses.json file\n",
        "file_id = '1yXFCvwFZamVwoiW5QFEdAtS_CT-2CZr-'\n",
        "\n",
        "# Define the output path for the downloaded file\n",
        "output_path = '/content/responses.json'\n",
        "\n",
        "# Download the file using gdown\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', output_path, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "X3NGIIAB5Dl8",
        "outputId": "f4a0a568-3138-423b-df4e-d25093d8d1a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yXFCvwFZamVwoiW5QFEdAtS_CT-2CZr-\n",
            "To: /content/responses.json\n",
            "100%|██████████| 11.5M/11.5M [00:00<00:00, 98.5MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/responses.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load the JSON data\n",
        "responses_file = '/content/responses.json'\n",
        "with open(responses_file, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Create a dictionary to map '_id' to ad_info for faster lookup\n",
        "ad_info_dict = {info['_id']: info for info in data.values() if '_id' in info}\n",
        "\n",
        "# Define the root directory for images\n",
        "images_dir = '/content/images'\n",
        "\n",
        "# Define the target dimensions for resizing images (lower resolution for efficiency)\n",
        "target_width = 512   # Lower resolution\n",
        "target_height = 512  # Lower resolution\n",
        "\n",
        "# Initialize lists to store calculated and extracted features\n",
        "campaign_data = []\n",
        "\n",
        "# Iterate through each image in the images directory\n",
        "for filename in os.listdir(images_dir):\n",
        "    if filename.endswith(\".jpg\"):  # Check if the file is a JPEG image\n",
        "        image_id = filename.split('.')[0]  # Extract ID from filename\n",
        "        if image_id in ad_info_dict:\n",
        "            ad_info = ad_info_dict[image_id]\n",
        "            image_path = os.path.join(images_dir, filename)\n",
        "\n",
        "            # Load and preprocess the image\n",
        "            with Image.open(image_path) as img:\n",
        "                img = img.convert('RGB')  # Convert image to RGB format\n",
        "                img = img.resize((target_width, target_height))  # Resize image to lower resolution\n",
        "                img_array = np.array(img)  # Convert image to numpy array\n",
        "\n",
        "            # Process only the necessary data to reduce memory load\n",
        "            avg_spend = np.mean([int(ad_info.get(\"spend\", {}).get(\"lower_bound\", 0)), int(ad_info.get(\"spend\", {}).get(\"upper_bound\", 0))])\n",
        "            avg_impressions = np.mean([int(ad_info.get(\"impressions\", {}).get(\"lower_bound\", 0)), int(ad_info.get(\"impressions\", {}).get(\"upper_bound\", 0))])\n",
        "            cost_per_impression = avg_spend / avg_impressions if avg_impressions > 0 else float('inf')\n",
        "\n",
        "            # Append only necessary info to reduce memory footprint\n",
        "            campaign_data.append({\n",
        "                \"ad_id\": ad_info.get('_id', ''),\n",
        "                \"cpi\": cost_per_impression,\n",
        "                \"image_data\": img_array.flatten().tolist()  # Flatten and convert to list to minimize size\n",
        "            })\n",
        "\n",
        "# Example: Print or save to file\n",
        "# for campaign in campaign_data[:3]:\n",
        "#     print(json.dumps(campaign, indent=2))\n",
        "\n",
        "# Instead of printing, consider saving processed data to disk to free memory\n",
        "import pickle\n",
        "with open('/content/campaign_data.pkl', 'wb') as f:\n",
        "    pickle.dump(campaign_data, f)\n",
        "\n",
        "# Clear the large variables from memory\n",
        "del campaign_data\n",
        "del data\n"
      ],
      "metadata": {
        "id": "LvGUsA3FczEx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the processed data from disk\n",
        "with open('/content/campaign_data.pkl', 'rb') as f:\n",
        "    campaign_data = pickle.load(f)\n",
        "\n",
        "# Print the first few entries of the campaign data to verify\n",
        "for campaign in campaign_data[:3]:  # Adjust the range as needed for more samples\n",
        "    print(\"Ad ID:\", campaign[\"ad_id\"])\n",
        "    print(\"Cost Per Impression (CPI):\", campaign[\"cpi\"])\n",
        "    print(\"Sample Image Data (flattened):\", campaign[\"image_data\"][:10])  # Show only the first 10 pixels to keep output manageable\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or7aFRU0YOCW",
        "outputId": "0d20af4d-7af3-4cfc-821d-4b9d194fafc1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ad ID: 1900522980255582\n",
            "Cost Per Impression (CPI): 0.06361933853342788\n",
            "Sample Image Data (flattened): [195, 195, 195, 196, 196, 196, 198, 198, 198, 199]\n",
            "\n",
            "\n",
            "Ad ID: 679507235777236\n",
            "Cost Per Impression (CPI): 0.01266008440056267\n",
            "Sample Image Data (flattened): [3, 37, 21, 4, 36, 21, 7, 35, 20, 8]\n",
            "\n",
            "\n",
            "Ad ID: 890876337968115\n",
            "Cost Per Impression (CPI): 0.02271838834898499\n",
            "Sample Image Data (flattened): [224, 217, 198, 225, 218, 199, 225, 218, 199, 226]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, image_filenames, labels, batch_size, image_directory, dim=(512, 512), n_channels=3, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.image_filenames = image_filenames\n",
        "        self.image_directory = image_directory\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.image_filenames) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        image_filenames_temp = [self.image_filenames[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(image_filenames_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.image_filenames))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, image_filenames_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size), dtype=float)\n",
        "\n",
        "        # Generate data\n",
        "        for i, image_filename in enumerate(image_filenames_temp):\n",
        "            # Store sample\n",
        "            img = load_img(os.path.join(self.image_directory, image_filename + '.jpg'), target_size=self.dim)\n",
        "            X[i,] = img_to_array(img) / 255.0\n",
        "\n",
        "            # Store class\n",
        "            y[i] = self.labels[image_filename]\n",
        "\n",
        "        return X, y\n"
      ],
      "metadata": {
        "id": "6LTXfo58bRoF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check TensorFlow GPU usage\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"TensorFlow will run on GPU\")\n",
        "else:\n",
        "    print(\"TensorFlow will run on CPU\")\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkfJ4SWO1odf",
        "outputId": "12964a16-fddf-4447-8792-ec5c619e0c21"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "TensorFlow will run on GPU\n",
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "def create_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(1)  # Assuming CPI prediction is a regression task\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Assuming you have a dictionary mapping from image IDs to CPI and file names\n",
        "image_filenames = [campaign['ad_id'] for campaign in campaign_data]  # ID is used as filename\n",
        "labels = {campaign['ad_id']: campaign['cpi'] for campaign in campaign_data}\n",
        "image_directory = '/content/images'\n",
        "\n",
        "# Splitting the dataset\n",
        "image_filenames_train, image_filenames_test, labels_train, labels_test = train_test_split(\n",
        "    image_filenames, [labels[id] for id in image_filenames], test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the generator\n",
        "batch_size = 10  # Depends on your available memory\n",
        "train_generator = DataGenerator(image_filenames=image_filenames_train, labels=dict(zip(image_filenames_train, labels_train)), batch_size=batch_size, image_directory=image_directory)\n",
        "test_generator = DataGenerator(image_filenames=image_filenames_test, labels=dict(zip(image_filenames_test, labels_test)), batch_size=batch_size, image_directory=image_directory)\n",
        "\n",
        "# Define your model's input shape based on the data dimensions you will train on\n",
        "input_shape = (512, 512, 3)  # Modify according to your resized image dimensions\n",
        "\n",
        "# Create the model\n",
        "model = create_model(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "# Show the model structure\n",
        "model.summary()\n",
        "# Now use this generator directly in model.fit\n",
        "model.fit(train_generator, epochs=10, validation_data=test_generator)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fedkgJPvcqG4",
        "outputId": "9aad23c5-1726-4aa1-b105-0f4d5fdbf1d7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 510, 510, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 255, 255, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 253, 253, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 126, 126, 64)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1016064)           0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               130056320 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 130075841 (496.20 MB)\n",
            "Trainable params: 130075841 (496.20 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "50/50 [==============================] - 18s 263ms/step - loss: 742.5449 - mean_absolute_error: 5.6868 - val_loss: 0.0024 - val_mean_absolute_error: 0.0376\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 13s 266ms/step - loss: 0.0045 - mean_absolute_error: 0.0416 - val_loss: 0.0019 - val_mean_absolute_error: 0.0334\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 13s 255ms/step - loss: 0.0034 - mean_absolute_error: 0.0362 - val_loss: 0.0016 - val_mean_absolute_error: 0.0297\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 13s 265ms/step - loss: 0.0028 - mean_absolute_error: 0.0332 - val_loss: 0.0014 - val_mean_absolute_error: 0.0274\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.0025 - mean_absolute_error: 0.0313 - val_loss: 0.0013 - val_mean_absolute_error: 0.0267\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 14s 270ms/step - loss: 0.0022 - mean_absolute_error: 0.0293 - val_loss: 0.0012 - val_mean_absolute_error: 0.0243\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.0020 - mean_absolute_error: 0.0272 - val_loss: 0.0011 - val_mean_absolute_error: 0.0227\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 13s 254ms/step - loss: 0.0019 - mean_absolute_error: 0.0241 - val_loss: 9.9158e-04 - val_mean_absolute_error: 0.0215\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 0.0018 - mean_absolute_error: 0.0251 - val_loss: 0.0010 - val_mean_absolute_error: 0.0224\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.0017 - mean_absolute_error: 0.0239 - val_loss: 9.6010e-04 - val_mean_absolute_error: 0.0214\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f793baea3b0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example dataset\n",
        "image_filenames = [f'{i}.jpg' for i in range(100)]  # Mock filenames\n",
        "labels = {f'{i}.jpg': np.random.randint(0, 2) for i in range(100)}  # Mock binary labels\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "image_filenames_train, image_filenames_test, _, _ = train_test_split(\n",
        "    image_filenames, list(labels.keys()), test_size=0.2, random_state=42)\n",
        "\n",
        "# Extract the labels for the training and testing sets\n",
        "labels_train = {filename: labels[filename] for filename in image_filenames_train}\n",
        "labels_test = {filename: labels[filename] for filename in image_filenames_test}\n",
        "\n",
        "\n",
        "# Create DataGenerator instances for training and testing\n",
        "train_generator = DataGenerator(\n",
        "    image_filenames=image_filenames_train,\n",
        "    labels=labels_train,\n",
        "    batch_size=10,\n",
        "    image_directory=image_directory\n",
        ")\n",
        "\n",
        "test_generator = DataGenerator(\n",
        "    image_filenames=image_filenames_test,\n",
        "    labels=labels_test,\n",
        "    batch_size=10,\n",
        "    image_directory=image_directory\n",
        ")\n"
      ],
      "metadata": {
        "id": "-B7TjFcQbdxD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xY-w5IVOC3Hc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d14e89-d5c2-4d23-a1d1-be2bda60b74d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 2s 188ms/step - loss: 9.9030e-04 - mean_absolute_error: 0.0222\n",
            "Test Loss: 0.0009903039317578077\n",
            "Mean Absolute Error (MAE): 0.022174907848238945\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_mae = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Mean Absolute Error (MAE): {test_mae}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('content/modelCPIComparison.h5')\n",
        "\n",
        "# Load the model\n",
        "#from tensorflow.keras.models import load_model\n",
        "#prod_model = load_model('modelCPIComparison.h5')\n"
      ],
      "metadata": {
        "id": "-fMSOyb16nvX"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}