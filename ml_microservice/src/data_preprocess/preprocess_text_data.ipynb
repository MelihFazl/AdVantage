{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "ads_dataset_path = '/content/drive/MyDrive/CS491MLMODEL/us/us/ads.json'\n",
    "ads_downsized_path = '/content/drive/MyDrive/CS491MLMODEL/us/us/ads_downsized.json'\n",
    "ads_non_duplicate_path = '/content/drive/MyDrive/CS491MLMODEL/us/us/ads_non_duplicate.json'\n",
    "ads_dataframe = '/content/drive/MyDrive/CS491MLMODEL/us/us/ads_dataframe.csv'\n",
    "ads_non_duplicate_path = '/content/drive/MyDrive/CS491MLMODEL/us/us/ads_non_duplicate.json'\n",
    "ads_dataframe_age_filtered = '/content/drive/MyDrive/CS491MLMODEL/us/us/ads_dataframe_age_filtered.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*DATA* DOWNSIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_item_heuristic = 3000000\n",
    "\n",
    "def downsize_data(num_of_items, input_dataset_path, output_dataset_path):\n",
    "    counter = 0\n",
    "    with open(input_dataset_path, 'r') as input_file:\n",
    "        parser = ijson.items(input_file, 'item')\n",
    "\n",
    "        with open(output_dataset_path, 'a') as outfile:  # Open output file once\n",
    "            outfile.write('[\\n')\n",
    "            # Use tqdm to create a progress bar\n",
    "            for item in tqdm(parser, total=int(num_of_items), unit=\" items\"):\n",
    "                if counter > num_of_items:\n",
    "                    break\n",
    "                counter += 1\n",
    "                json.dump(item, outfile)\n",
    "                if counter > num_of_items:\n",
    "                  outfile.write('\\n')  # Add a newline between items\n",
    "                else:\n",
    "                  outfile.write(',\\n')  # Add a newline between items\n",
    "\n",
    "            outfile.write(']\\n')\n",
    "            outfile.close()\n",
    "\n",
    "downsize_data(json_item_heuristic, ads_dataset_path, ads_downsized_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA DUPLICATE REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(filename, column, output_filename):\n",
    "    json_item_heuristic = 3000\n",
    "    first_item = True\n",
    "    removed_content = 0\n",
    "    unique_values = set()\n",
    "\n",
    "    with open(filename, 'rb') as file:\n",
    "        items = ijson.items(file, 'item')\n",
    "\n",
    "        with open(output_filename, 'w') as outfile:\n",
    "            outfile.write('[\\n')\n",
    "            for item in tqdm(items, total=int(json_item_heuristic), unit=\" items\"):\n",
    "                if 'ad_creative_bodies' in item:\n",
    "                    column_value = tuple(item['ad_creative_bodies'])\n",
    "\n",
    "                    if (column_value not in unique_values) and (len(column_value) == 1):\n",
    "                        unique_values.add(column_value)\n",
    "                        if first_item:\n",
    "                            json.dump(item, outfile)\n",
    "                            first_item = False\n",
    "                        else:\n",
    "                            outfile.write(',\\n')\n",
    "                            json.dump(item, outfile)\n",
    "                    else:\n",
    "                        removed_content += 1\n",
    "                else:\n",
    "                    removed_content += 1\n",
    "                    pass\n",
    "            outfile.write(']\\n')\n",
    "    print(f\"Amount of ads that have been filtered: {removed_content}\")\n",
    "\n",
    "\n",
    "remove_duplicates(ads_downsized_path, 'a', ads_non_duplicate_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON TO CSV CONVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ads_non_duplicate_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "processed_data = []\n",
    "for item in data:\n",
    "    selected_attributes = {'ad_creation_time': item['ad_creation_time'],\n",
    "                           'ad_creative_bodies': item['ad_creative_bodies'],\n",
    "                           'currency': item['currency'],\n",
    "                           'impressions': item['impressions'],\n",
    "                           'spend': item['spend']}\n",
    "    processed_data.append(selected_attributes)\n",
    "\n",
    "df = pd.DataFrame(processed_data)\n",
    "\n",
    "df.to_csv(ads_dataframe, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATAFRAME & GET INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ads_dataframe)\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERT INTO DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "\n",
    "new_df['ad_creation_time'] = pd.to_datetime(df['ad_creation_time'])\n",
    "new_df['ad_creative_bodies'] = df['ad_creative_bodies'].apply(lambda x: ast.literal_eval(x)[0] if pd.notnull(x) else x).astype(str)\n",
    "\n",
    "\n",
    "# Extract 'lower_bound' and 'upper_bound' values if they exist, otherwise use NaN\n",
    "new_df['impressions_lower'] = df['impressions'].apply(lambda x: ast.literal_eval(x).get('lower_bound', None)).astype(\"float\")\n",
    "new_df['impressions_upper'] = df['impressions'].apply(lambda x: ast.literal_eval(x).get('upper_bound', None)).astype(\"float\")\n",
    "\n",
    "new_df['spend_lower'] = df['spend'].apply(lambda x: ast.literal_eval(x).get('lower_bound', None)).astype(\"float\")\n",
    "new_df['spend_upper'] = df['spend'].apply(lambda x: ast.literal_eval(x).get('upper_bound', None)).astype(\"float\")\n",
    "\n",
    "print(new_df.dtypes)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGE COLUMNS AND SORT ACCORDING TO DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_dataframe = pd.DataFrame()\n",
    "ads_dataframe['ad_creation_time'] = new_df['ad_creation_time']\n",
    "ads_dataframe['ad_creative_bodies'] = new_df['ad_creative_bodies']\n",
    "ads_dataframe['cpi'] = (\n",
    "    (new_df['spend_lower'].fillna(new_df['spend_upper']) / 2 +\n",
    "     new_df['spend_upper'].fillna(new_df['spend_lower']) / 2) /\n",
    "    (new_df['impressions_lower'].fillna(new_df['impressions_upper']) / 2 +\n",
    "     new_df['impressions_upper'].fillna(new_df['impressions_lower']) / 2)\n",
    ")\n",
    "\n",
    "ads_dataframe = ads_dataframe.sort_values(by='ad_creation_time')\n",
    "ads_dataframe"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
